{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1diwgfuV6WJuDhz5hfAIKot4pgNH02X4y","authorship_tag":"ABX9TyNPvPW6E5Ptj3se7q+N1gyO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### To install libraries"],"metadata":{"id":"yCx6qDFfSsP9"}},{"cell_type":"code","source":["!pip install scrapy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K__57k1rSgm_","executionInfo":{"status":"ok","timestamp":1694421768743,"user_tz":-330,"elapsed":13016,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}},"outputId":"2319f57a-edb1-4b9d-e6a3-df999240f0b0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scrapy\n","  Downloading Scrapy-2.10.1-py2.py3-none-any.whl (281 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Twisted<23.8.0,>=18.9.0 (from scrapy)\n","  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (41.0.3)\n","Collecting cssselect>=0.9.1 (from scrapy)\n","  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n","Collecting itemloaders>=1.0.1 (from scrapy)\n","  Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n","Collecting parsel>=1.5.0 (from scrapy)\n","  Downloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n","Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (23.2.0)\n","Collecting queuelib>=1.4.2 (from scrapy)\n","  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n","Collecting service-identity>=18.1.0 (from scrapy)\n","  Downloading service_identity-23.1.0-py3-none-any.whl (12 kB)\n","Collecting w3lib>=1.17.0 (from scrapy)\n","  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n","Collecting zope.interface>=5.1.0 (from scrapy)\n","  Downloading zope.interface-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting protego>=0.1.15 (from scrapy)\n","  Downloading Protego-0.3.0-py2.py3-none-any.whl (8.5 kB)\n","Collecting itemadapter>=0.1.0 (from scrapy)\n","  Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from scrapy) (67.7.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from scrapy) (23.1)\n","Collecting tldextract (from scrapy)\n","  Downloading tldextract-3.5.0-py3-none-any.whl (97 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.2/97.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (4.9.3)\n","Collecting PyDispatcher>=2.0.5 (from scrapy)\n","  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->scrapy) (1.15.1)\n","Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (23.1.0)\n","Requirement already satisfied: pyasn1 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.5.0)\n","Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.3.0)\n","Collecting constantly>=15.1 (from Twisted<23.8.0,>=18.9.0->scrapy)\n","  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n","Collecting incremental>=21.3.0 (from Twisted<23.8.0,>=18.9.0->scrapy)\n","  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n","Collecting Automat>=0.8.0 (from Twisted<23.8.0,>=18.9.0->scrapy)\n","  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n","Collecting hyperlink>=17.1.1 (from Twisted<23.8.0,>=18.9.0->scrapy)\n","  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (4.5.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.4)\n","Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (2.31.0)\n","Collecting requests-file>=1.4 (from tldextract->scrapy)\n","  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.12.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Automat>=0.8.0->Twisted<23.8.0,>=18.9.0->scrapy) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.2.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2023.7.22)\n","Installing collected packages: PyDispatcher, incremental, constantly, zope.interface, w3lib, queuelib, protego, jmespath, itemadapter, hyperlink, cssselect, Automat, Twisted, requests-file, parsel, tldextract, service-identity, itemloaders, scrapy\n","Successfully installed Automat-22.10.0 PyDispatcher-2.0.7 Twisted-22.10.0 constantly-15.1.0 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 parsel-1.8.1 protego-0.3.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.10.1 service-identity-23.1.0 tldextract-3.5.0 w3lib-2.1.2 zope.interface-6.0\n"]}]},{"cell_type":"markdown","source":["### Importing Libraries"],"metadata":{"id":"6X_Iz2jNSoeK"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"o3ZwZ1ERR_RH","executionInfo":{"status":"ok","timestamp":1694421792295,"user_tz":-330,"elapsed":1667,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}}},"outputs":[],"source":["import os\n","from bs4 import BeautifulSoup\n","import urllib\n","from urllib.request import Request\n","#import urllib2\n","import pandas as pd\n","from lxml import html\n","import re\n","import requests\n","from string import ascii_uppercase\n","import random\n","from itertools import islice, count\n","from tqdm import tqdm\n","from scrapy.http import HtmlResponse\n","import math\n","import datetime"]},{"cell_type":"markdown","source":["### Input variables from users"],"metadata":{"id":"Hkr3uYhnS53f"}},{"cell_type":"code","source":["path2 = r'/content/drive/MyDrive/GITHUB/PROJECT1' ## destination path location to store final files\n","comp_folder ='BP' ## company's name\n","comp_list = ['BP'] ## exact name of the company which is mentioned in Glassdoor URL after 'Reviews'\n","e_list = ['E9011'] ## exact code of the company which is mentioned in Glassdoor URL after 'Reviews'\n","# For eg: https://www.glassdoor.co.in/Reviews/BP-Reviews-E9011_P1.htm"],"metadata":{"id":"9EiBeyMfSY0_","executionInfo":{"status":"ok","timestamp":1694423511105,"user_tz":-330,"elapsed":6,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def build_url2(url, company_name, url_specific):\n","    return url + '/Reviews/' + company_name + '-Reviews-' + url_specific + '_P'\n","\n","def get_reviews(review_url, comp, path):\n","    review_df = pd.DataFrame()\n","    review_rating, review_title,reviewer_job, reviewer_location, pro_review_text, con_review_text, review_date= [],[],[],[],[],[],[],[]\n","    try:\n","        itr = int(review_url[review_url.find('_P')+2:review_url.rfind('.htm')])\n","        url = urllib.request.urlopen(Request(review_url,headers=hdr))\n","        soup = BeautifulSoup(url,\"html.parser\")\n","        #soup = BeautifulSoup(url,\"lxml\")\n","        containers=soup.findAll('div',{'class':'review-details__review-details-module__topReview'})\n","        print(len(containers))\n","\n","        if len(containers) == 0:\n","            #soup = BeautifulSoup(url,\"html.parser\")\n","            soup = BeautifulSoup(url,\"lxml\")\n","            containers=soup.findAll('div',{'class':'review-details__review-details-module__topReview'})\n","            print(len(containers))\n","\n","        for c in containers:\n","            try:\n","                review_title.append(c.find('a', {'class': 'review-details__review-details-module__detailsLink review-details__review-details-module__title'}).text)\n","            except:\n","                review_title.append('NA')\n","            try:\n","                review_rating.append(c.find('span', {'class': 'review-details__review-details-module__overallRating'}).text)\n","            except:\n","                review_rating.append('NA')\n","            try:\n","                reviewer_job.append(c.find('span', {'class': 'review-details__review-details-module__employee'}).text)\n","            except:\n","                reviewer_job.append('NA')\n","            try:\n","                reviewer_location.append(c.find('span', {'class': 'review-details__review-details-module__location'}).text)\n","            except:\n","                reviewer_location.append('NA')\n","            try:\n","                pro_review_text.append(c.find('span', {'data-test': 'pros'}).text)\n","            except:\n","               pro_review_text.append('NA')\n","            try:\n","                con_review_text.append(c.find('span', {'data-test': 'cons'}).text)\n","            except:\n","               con_review_text.append('NA')\n","            try:\n","                review_date.append(c.find('span', {'class': 'review-details__review-details-module__reviewDate'}).text)\n","            except:\n","                review_date.append('NA')\n","\n","        df = pd.DataFrame(list(zip(review_rating, review_title,reviewer_job, reviewer_location, pro_review_text, con_review_text, review_date)))\n","        df.columns=['Review_Rating', 'Review_Title', 'Job_Title', 'Job_Location', 'Pro_Review', 'Con_Review', 'Date_of_Review']\n","        df['Company'] = comp\n","        review_df = review_df.append(df)\n","        review_df = review_df.drop_duplicates()\n","        review_df.to_excel(path + '/review_data/glassdoor_review_' + comp + str(itr) + '.xlsx', index=False)\n","    except:\n","        print(review_url)"],"metadata":{"id":"oYUfdCkWTeZ8","executionInfo":{"status":"ok","timestamp":1694421955140,"user_tz":-330,"elapsed":553,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["## Start of the code\n","if __name__=='__main__':\n","  base_url = \"https://www.glassdoor.co.in\"\n","  hdr = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n","  sub1 = \"of\"\n","  sub2 = \"Reviews\"\n","  s=str(re.escape(sub1))\n","  e=str(re.escape(sub2))\n","  for each in range(len(comp_list)):\n","    company = comp_list[each]\n","    base = build_url2(base_url,company,e_list[each])\n","    review_url = base + '1.htm'\n","    url = urllib.request.urlopen(Request(review_url,headers=hdr))\n","    soup = BeautifulSoup(url,\"html.parser\")\n","    max_pages = math.ceil(pd.to_numeric(re.sub(',','',re.findall(s+'(.*)'+e,soup.findAll('div',{'class':'paginationFooter'})[-1].find('span').text)[0].strip()))/10)\n","\n","    page_range = list(range(1, max_pages+1))\n","    review_urls = [f'{base}{str(x)}.htm' for \\\n","               x in page_range]\n","\n","    from joblib import parallel_backend, Parallel, delayed\n","    gen = count(0, 1)\n","    with parallel_backend('threading', n_jobs=8):\n","        Parallel()(delayed(get_reviews)(review_url, comp=company,path=path+'/'+comp_folder) for review_url in tqdm(review_urls, position=0, leave=True))\n","\n","    from glob import glob\n","    file_list = glob(path+'/'+comp_folder + '/review_data/glassdoor_review_' + company + '*.xlsx')\n","    df_list = [pd.read_excel(file) for file in file_list]\n","    complete_df = pd.concat(df_list, axis=0).drop_duplicates()\n","    complete_df.to_excel(path+'/'+comp_folder + '/Data/' + company + '_glassdoor_reviews_complete.xlsx', index=False)"],"metadata":{"id":"1uLhBs-uUBzN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["url = urllib.request.urlopen(Request(review_url,headers=hdr))"],"metadata":{"id":"rYJ-CFTna9K6","executionInfo":{"status":"ok","timestamp":1694422085742,"user_tz":-330,"elapsed":942,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["soup = BeautifulSoup(url,\"html.parser\")"],"metadata":{"id":"SKe7C6l3bSf1","executionInfo":{"status":"ok","timestamp":1694422137142,"user_tz":-330,"elapsed":1325,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["max_pages = math.ceil(pd.to_numeric(re.sub(',','',re.findall(s+'(.*)'+e,soup.findAll('div',{'class':'paginationFooter'})[-1].find('span').text)[0].strip()))/10)"],"metadata":{"id":"bgRReOMMbe6x","executionInfo":{"status":"ok","timestamp":1694423170699,"user_tz":-330,"elapsed":517,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["max_pages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KeUjkFpue58E","executionInfo":{"status":"ok","timestamp":1694423181279,"user_tz":-330,"elapsed":11,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}},"outputId":"4d5825b2-6e77-44ab-adcf-ace54f7e1428"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["348"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["page_range = list(range(1, max_pages+1))\n","review_urls = [f'{base}{str(x)}.htm' for x in page_range]"],"metadata":{"id":"fqdZ5-fufeP2","executionInfo":{"status":"ok","timestamp":1694423238936,"user_tz":-330,"elapsed":3,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["review_urls[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"6pVNQ2rbf2u7","executionInfo":{"status":"ok","timestamp":1694423465294,"user_tz":-330,"elapsed":9,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}},"outputId":"3e742cc1-d13b-4a95-cb2c-a31c589494e6"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'https://www.glassdoor.co.in/Reviews/BP-Reviews-E9011_P1.htm'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["review_url = review_urls[0]\n","comp = company\n","path = path2+'/'+comp_folder"],"metadata":{"id":"9N6iC7cYfsJL","executionInfo":{"status":"ok","timestamp":1694423519266,"user_tz":-330,"elapsed":2,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["review_df = pd.DataFrame()\n","review_rating, review_title,reviewer_job, reviewer_location, review_text, pro_review_text, con_review_text, review_date= [],[],[],[],[],[],[],[]"],"metadata":{"id":"2iVKTyCqgwVJ","executionInfo":{"status":"ok","timestamp":1694423540198,"user_tz":-330,"elapsed":6,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["itr = int(review_url[review_url.find('_P')+2:review_url.rfind('.htm')])\n","url = urllib.request.urlopen(Request(review_url,headers=hdr))\n","soup = BeautifulSoup(url,\"html.parser\")\n","#soup = BeautifulSoup(url,\"lxml\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYIUmxDYg11F","executionInfo":{"status":"ok","timestamp":1694423574527,"user_tz":-330,"elapsed":1411,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}},"outputId":"758c34c1-86ee-4cd0-d8e5-1996c0a1b8bb"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}]},{"cell_type":"code","source":["containers=soup.findAll('div',{'class':'review-details__review-details-module__topReview'})\n","print(len(containers))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MdiZ6tKng90N","executionInfo":{"status":"ok","timestamp":1694424143693,"user_tz":-330,"elapsed":6,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}},"outputId":"f31ea6f3-0a0e-4c02-e3ae-661ddf441cd9"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["10\n"]}]},{"cell_type":"code","source":["c = containers[0]"],"metadata":{"id":"l3PLG3UoiOxe","executionInfo":{"status":"ok","timestamp":1694424187178,"user_tz":-330,"elapsed":4,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["c.find('span', {'class': 'review-details__review-details-module__reviewDate'}).text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"wqXrwVnvjTqy","executionInfo":{"status":"ok","timestamp":1694425145985,"user_tz":-330,"elapsed":6,"user":{"displayName":"Taru Agarwal","userId":"06943546457686899005"}},"outputId":"f1720b87-bed3-4335-885a-41f46dcae3dc"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'22 Aug 2023'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":[],"metadata":{"id":"7qMBaiEAjUhc"},"execution_count":null,"outputs":[]}]}